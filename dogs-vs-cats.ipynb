{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.6-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python36664bit1a0c77cea0c4420d8871c611f72e362e",
   "display_name": "Python 3.6.6 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import argparse\n",
    "\n",
    "\n",
    "###################################################################\n",
    "# Variables #\n",
    "# When launching project or scripts from Visual Studio, #\n",
    "# input_dir and output_dir are passed as arguments.  #\n",
    "# Users could set them from the project setting page.  #\n",
    "###################################################################\n",
    "input_dir = '.'\n",
    "output_dir = 'output'\n",
    "log_dir = 'logs'\n",
    "train_data_dir = 'data/train'\n",
    "validation_data_dir = 'data/validation'\n",
    "img_width, img_height = 150, 150\n",
    "batch_size = 32\n",
    "epochs = 1\n",
    "train_samples = 2048\n",
    "validation_samples = 832\n",
    "desired_size = 150\n",
    "\n",
    "#################################################################################\n",
    "# Keras configs.  #\n",
    "# Please refer to https://keras.io/backend .  #\n",
    "#################################################################################\n",
    "import keras\n",
    "from keras import backend as K\n",
    "\n",
    "#K.set_floatx('float32')\n",
    "#String: 'float16', 'float32', or 'float64'.\n",
    "\n",
    "#K.set_epsilon(1e-05)\n",
    "#float.  Sets the value of the fuzz factor used in numeric expressions.\n",
    "\n",
    "#K.set_image_data_format('channels_first')\n",
    "#data_format: string.  'channels_first' or 'channels_last'.\n",
    "\n",
    "\n",
    "#################################################################################\n",
    "# Keras imports.  #\n",
    "#################################################################################\n",
    "from keras import applications\n",
    "from keras.models import Model\n",
    "from keras.models import load_model\n",
    "from keras.models import Sequential\n",
    "from keras.models import model_from_json\n",
    "from keras.layers import Input\n",
    "from keras.layers import Lambda\n",
    "from keras.layers import Layer\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import ZeroPadding2D\n",
    "from keras import optimizers\n",
    "from keras.optimizers import SGD\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.image import array_to_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import load_img\n",
    "from PIL import Image\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1. / 255)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keras_augment():\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "    image = load_img('data/train/dogs/dog.0.jpg')\n",
    "    x = img_to_array(image)  \n",
    "    x = x.reshape((1,) + x.shape)  # this is a Numpy array with shape (1, 3, 150, 150)\n",
    "\n",
    "    # the .flow() command below generates batches of randomly transformed images\n",
    "    # and saves the results to the `preview/` directory\n",
    "    i = 0\n",
    "    for batch in datagen.flow(x, batch_size=1,\n",
    "                              save_to_dir='preview', save_prefix='dog', save_format='jpeg'):\n",
    "        i += 1\n",
    "        if i > 20:\n",
    "            break  # otherwise the generator would loop indefinitely\n",
    "\n",
    "def small_cnn():\n",
    "    # a simple stack of 3 convolution layers with a ReLU activation and\n",
    "    # followed by max-pooling layers.\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(32, (3, 3), input_shape=(img_width, img_height,3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Convolution2D(32, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Convolution2D(64, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='SGD',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "def save_model(model, name):\n",
    "    # serialize model to JSON\n",
    "    model_json = model.to_json()\n",
    "    with open(\"output/\" + name + \".json\", \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    # serialize weights to HDF5\n",
    "    model.save_weights(\"output/\" + name + \".h5\")\n",
    "\n",
    "def train_smallcnn():\n",
    "    # automagically retrieve images and their classes for train and validation\n",
    "    # sets\n",
    "    train_generator = datagen.flow_from_directory(train_data_dir,\n",
    "            target_size=(img_width, img_height),\n",
    "            batch_size=batch_size,\n",
    "            class_mode='binary')\n",
    "\n",
    "    validation_generator = datagen.flow_from_directory(validation_data_dir,\n",
    "            target_size=(img_width, img_height),\n",
    "            batch_size=batch_size,\n",
    "            class_mode='binary')\n",
    "\n",
    "    # get model\n",
    "    model = small_cnn()\n",
    "\n",
    "    # train this model on the dataset\n",
    "    model.fit_generator(train_generator,\n",
    "            steps_per_epoch=train_samples // batch_size,\n",
    "            epochs=epochs,\n",
    "            validation_data=validation_generator,\n",
    "            validation_steps=validation_samples // batch_size, verbose=1)\n",
    "\n",
    "    # save the model weights\n",
    "    save_model(model, \"basic_cnn\")\n",
    "    return model, validation_generator, validation_samples\n",
    "\n",
    "def evaluate(model, validation_generator, validation_samples):\n",
    "    result = model.evaluate_generator(validation_generator, validation_samples)\n",
    "    return result\n",
    "\n",
    "def train_augmented_data():\n",
    "    # Augment images and their classes for train and validation sets\n",
    "    train_datagen = ImageDataGenerator(rescale=1. / 255,        # normalize pixel values to [0,1]\n",
    "            shear_range=0.2,       # randomly applies shearing transformation\n",
    "            zoom_range=0.2,        # randomly applies zoom transformation\n",
    "            horizontal_flip=True)  # randomly flip the images\n",
    "\n",
    "    # same code as before\n",
    "    train_generator = train_datagen.flow_from_directory(train_data_dir,\n",
    "            target_size=(img_width, img_height),\n",
    "            batch_size=batch_size,\n",
    "            class_mode='binary')\n",
    "\n",
    "    validation_generator = datagen.flow_from_directory(validation_data_dir,\n",
    "            target_size=(img_width, img_height),\n",
    "            batch_size=batch_size,\n",
    "            class_mode='binary')\n",
    "\n",
    "    # get model\n",
    "    model = small_cnn()\n",
    "\n",
    "    # Training the model with augmented data\n",
    "    model.fit_generator(train_generator,\n",
    "            steps_per_epoch=train_samples // batch_size,\n",
    "            epochs=epochs,\n",
    "            validation_data=validation_generator,\n",
    "            validation_steps=validation_samples // batch_size,)\n",
    "\n",
    "    # save the model weights\n",
    "    save_model(model, 'basic_cnn_augmented')\n",
    "    return model, validation_generator, validation_samples\n",
    "\n",
    "def use_pretrained_model():\n",
    "    # Using a pretrained model\n",
    "    # Loading the model\n",
    "    model_vgg = applications.VGG16(include_top=False, weights='imagenet', input_shape=(150, 150, 3))\n",
    "\n",
    "    train_generator = datagen.flow_from_directory(train_data_dir,\n",
    "            target_size=(img_width, img_height),\n",
    "            batch_size=batch_size,\n",
    "            class_mode=None,\n",
    "            shuffle=False)\n",
    "\n",
    "    validation_generator = datagen.flow_from_directory(validation_data_dir,\n",
    "            target_size=(img_width, img_height),\n",
    "            batch_size=batch_size,\n",
    "            class_mode=None,\n",
    "            shuffle=False)\n",
    "\n",
    "    # Save the features weights\n",
    "    features_train = model_vgg.predict_generator(train_generator, train_samples // batch_size)\n",
    "    np.save(open('output/features_train.npy', 'wb'), features_train)\n",
    "\n",
    "    # Save the validation weights\n",
    "    features_validation = model_vgg.predict_generator(validation_generator, validation_samples // batch_size)\n",
    "    np.save(open('output/features_validation.npy', 'wb'), features_validation)\n",
    "\n",
    "    # Load the weights\n",
    "    train_data = np.load(open('output/features_train.npy', 'rb'))\n",
    "    train_labels = np.array([0] * (train_samples // 2) + [1] * (train_samples // 2))\n",
    "\n",
    "    validation_data = np.load(open('output/features_validation.npy', 'rb'))\n",
    "    validation_labels = np.array([0] * (validation_samples // 2) + [1] * (validation_samples // 2))\n",
    "\n",
    "    # Define the fully connected network\n",
    "    model_top = Sequential()\n",
    "    model_top.add(Flatten(input_shape=train_data.shape[1:]))\n",
    "    model_top.add(Dense(256, activation='relu'))\n",
    "    model_top.add(Dropout(0.5))\n",
    "    model_top.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model_top.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Train the model now\n",
    "    model_top.fit(train_data, train_labels,\n",
    "            epochs=epochs, \n",
    "            batch_size=batch_size,\n",
    "            validation_data=(validation_data, validation_labels))\n",
    "\n",
    "    # Train the model now\n",
    "    model_top.fit(train_data, train_labels,\n",
    "            epochs=epochs, \n",
    "            batch_size=batch_size,\n",
    "            validation_data=(validation_data, validation_labels))\n",
    "\n",
    "    # Save the weights from this model\n",
    "    save_model(model_top, 'bottleneck')\n",
    "    return model_top, validation_data, validation_labels\n",
    "\n",
    "def finetune_model():\n",
    "    # Loading the model\n",
    "    model_vgg = applications.VGG16(include_top=False, weights='imagenet', input_shape=(150, 150, 3))\n",
    "\n",
    "    # Start with a fully trained-classifer\n",
    "    top_model = Sequential()\n",
    "    top_model.add(Flatten(input_shape=model_vgg.output_shape[1:]))\n",
    "    top_model.add(Dense(256, activation='relu'))\n",
    "    top_model.add(Dropout(0.5))\n",
    "    top_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Use the weights from the earlier model\n",
    "    top_model.load_weights('output/bottleneck.h5')\n",
    "\n",
    "    # Add this model on top of the convolutional base.\n",
    "    model = Model(inputs = model_vgg.input, outputs = top_model(model_vgg.output))\n",
    "\n",
    "    # Fine-tuning needs training only a few layers.  Set first 25 layers as\n",
    "    # non-trainable\n",
    "    for layer in model.layers[:15]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # compile the model with a SGD/momentum optimizer\n",
    "    # and a very slow learning rate.\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # Augment data and\n",
    "    train_datagen = ImageDataGenerator(rescale=1. / 255,\n",
    "            shear_range=0.2,\n",
    "            zoom_range=0.2,\n",
    "            horizontal_flip=True)\n",
    "\n",
    "    test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(train_data_dir,\n",
    "            target_size=(img_height, img_width),\n",
    "            batch_size=batch_size,\n",
    "            class_mode='binary')\n",
    "\n",
    "    validation_generator = test_datagen.flow_from_directory(validation_data_dir,\n",
    "            target_size=(img_height, img_width),\n",
    "            batch_size=batch_size,\n",
    "            class_mode='binary')\n",
    "\n",
    "    # fine-tune the model\n",
    "    model.fit_generator(train_generator,\n",
    "        steps_per_epoch=train_samples // batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=validation_samples // batch_size)\n",
    "\n",
    "    save_model(model, 'finetuned_model')\n",
    "    return model, validation_generator, validation_samples\n",
    "\n",
    "def load_image(img_path, show=False):\n",
    "\n",
    "    img = image.load_img(img_path, target_size=(150, 150))\n",
    "    img_tensor = image.img_to_array(img)                    # (height, width, channels)\n",
    "    img_tensor = np.expand_dims(img_tensor, axis=0)         # (1, height, width, channels), add a dimension because the model expects this shape: (batch_size, height, width, channels)\n",
    "    img_tensor /= 255.                                      # imshow expects values in the range [0, 1]\n",
    "\n",
    "    if show:\n",
    "        plt.imshow(img_tensor[0])                           \n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "    return img_tensor\n",
    "\n",
    "def predict_image():\n",
    "    # loading model\n",
    "    json_file = open('output/finetuned_model.json', 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    model = model_from_json(loaded_model_json)\n",
    "    # load weights into new model\n",
    "    model.load_weights(\"output/finetuned_model.h5\")\n",
    "\n",
    "    # URL\n",
    "    #sample_file_url = \"https://shop.epictv.com/sites/default/files/ae42ad29e70ba8ce6b67d3bdb6ab5c6e.jpeg\"\n",
    "    #fd = urllib.urlopen(sample_file_url)\n",
    "    #raw_data = io.BytesIO(fd.read())\n",
    "    #image = Image.open(raw_data)\n",
    "\n",
    "    for root, dirs, files in os.walk('modelfiles/test_images'):\n",
    "        for name in files:\n",
    "            image_path = os.path.join(root, name)\n",
    "            image = Image.open(image_path)\n",
    "            image = image.convert('RGB')\n",
    "            old_size = image.size\n",
    "            #Taking the max from height and width of the image and calculating ratio\n",
    "            ratio = float(desired_size)/max(old_size)\n",
    "            new_size = tuple([int(x*ratio) for x in old_size])\n",
    "\n",
    "            image = image.resize(new_size, Image.ANTIALIAS)\n",
    "            new_im = Image.new(\"RGB\", (desired_size, desired_size), (255,255,255)) #creating RGB image and applying white mask for blank area\n",
    "            new_im.paste(image, ((desired_size-new_size[0])//2, (desired_size-new_size[1])//2))\n",
    "        \n",
    "            x = np.asarray(new_im, dtype='float32')\n",
    "            #x = x.transpose(2, 0, 1)\n",
    "            x = np.expand_dims(x, axis=0)\n",
    "            out = model.predict(x)\n",
    "            print(name, out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    ### Augmenting data\n",
    "    #keras_augment()\n",
    "\n",
    "    ### 1 - build a small cnn model\n",
    "    print('training simple cnn...')\n",
    "    model, validation_generator, validation_samples = train_smallcnn()\n",
    "    print('training completed.')\n",
    "    \n",
    "    #print('evaluating model...')\n",
    "    #eval = evaluate(model, validation_generator, validation_samples)\n",
    "    #print(eval)\n",
    "\n",
    "    ### 2 - training with augmented data, useful for increasing accuracy\n",
    "    #print('training with augmented data...')\n",
    "    #model, validation_generator, validation_samples = train_augmented_data()\n",
    "\n",
    "    #print('evaluating model...')\n",
    "    #eval = evaluate(model, validation_generator, validation_samples)\n",
    "    #print(eval)\n",
    "\n",
    "    ### 3 - training a pretrained model\n",
    "    #print('training a pretrained model...')\n",
    "    #model, validation_data, validation_labels = use_pretrained_model()\n",
    "\n",
    "    #print('evaluating the model...')\n",
    "    #eval = model.evaluate(validation_data, validation_labels)\n",
    "    #print(eval)\n",
    "\n",
    "    ### 4 - finetuning model\n",
    "    #print('finetuning model...')\n",
    "    #model, validation_generator, validation_samples = finetune_model()\n",
    "\n",
    "    #print('evaluating the model...')\n",
    "    #eval = evaluate(model, validation_generator, validation_samples)\n",
    "    #print(eval)\n",
    "\n",
    "    ## 5 - using model to predict category\n",
    "    print('predicting images...')\n",
    "    predict_image()\n",
    "\n",
    "    #input('press enter to continue...')\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--input_dir\", type=str, \n",
    "                        default=None, \n",
    "                        help=\"Input directory where where training dataset and meta data are saved\", \n",
    "                        required=False)\n",
    "    parser.add_argument(\"--output_dir\", type=str, \n",
    "                        default=None, \n",
    "                        help=\"Input directory where where logs and models are saved\", \n",
    "                        required=False)\n",
    "\n",
    "    args, unknown = parser.parse_known_args()\n",
    "    input_dir = args.input_dir\n",
    "    output_dir = args.output_dir\n",
    "    log_dir = output_dir\n",
    "\n",
    "    main()\n"
   ]
  }
 ]
}